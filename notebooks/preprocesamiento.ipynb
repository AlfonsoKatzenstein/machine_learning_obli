{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3442cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Config paths (robusto para VS Code)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Si se ejecuta el notebook desde /notebooks, subimos un nivel al raíz del proyecto\u001b[39;00m\n\u001b[1;32m      6\u001b[0m PROJ \u001b[38;5;241m=\u001b[39m Path\u001b[38;5;241m.\u001b[39mcwd() \u001b[38;5;28;01mif\u001b[39;00m (Path\u001b[38;5;241m.\u001b[39mcwd()\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebooks\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m Path\u001b[38;5;241m.\u001b[39mcwd()\u001b[38;5;241m.\u001b[39mparent\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Config paths (robusto para VS Code)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Si se ejecuta el notebook desde /notebooks, subimos un nivel al raíz del proyecto\n",
    "PROJ = Path.cwd() if (Path.cwd().name != \"notebooks\") else Path.cwd().parent\n",
    "DATA = PROJ / \"data\"\n",
    "\n",
    "train_path = DATA / \"train.csv\"\n",
    "assert train_path.exists(), f\"No encuentro {train_path}. ¿Está en /data?\"\n",
    "\n",
    "test_path = DATA / \"test.csv\"\n",
    "assert test_path.exists(), f\"No encuentro {test_path}. ¿Está en /data?\"\n",
    "\n",
    "# Carga de datos\n",
    "train = pd.read_csv(train_path)  # si pesa mucho, podés usar low_memory=True\n",
    "print(\"Shape:\", train.shape)\n",
    "display(train.head())\n",
    "\n",
    "# Carga de datos\n",
    "test = pd.read_csv(test_path)\n",
    "print(\"Shape:\", test.shape)\n",
    "display(test.head())\n",
    "\n",
    "# Chequeos básicos\n",
    "print(\"\\nTipos:\")\n",
    "print(train.dtypes)\n",
    "print(\"\\nNulos (top 10):\")\n",
    "print(train.isna().sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219dcf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#GESTION DE VALORES NULOS O FALTANTES\n",
    "\n",
    "# Separar la variable objetivo\n",
    "target_col = \"popularity\"\n",
    "\n",
    "X_train = train.drop(columns=[target_col])\n",
    "y_train = train[target_col]\n",
    "\n",
    "# Detectar columnas numéricas y categóricas SOLO en X_train\n",
    "num_cols = X_train.select_dtypes(include=['number']).columns\n",
    "cat_cols = X_train.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Definir el preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "        (\"cat\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\"), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Ajustar solo con X_train (sin popularity)\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# Transformar train y test\n",
    "train_prepared = preprocessor.transform(X_train)\n",
    "test_prepared  = preprocessor.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aae960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NUMÉRICAS CONTINUAS: solo estas variables tienen sentido para outliers\n",
    "num_continuous = [\n",
    "    \"duration_ms\",\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"loudness\",\n",
    "    \"speechiness\",\n",
    "    \"acousticness\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"valence\",\n",
    "    \"tempo\"\n",
    "]\n",
    "\n",
    "# 1. VISUALIZACIÓN DE OUTLIERS\n",
    "fig, axes = plt.subplots(len(num_continuous)//3 + 1, 3, figsize=(15, len(num_continuous)*2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(num_continuous):\n",
    "    sns.boxplot(x=train[col], ax=axes[i])\n",
    "    axes[i].set_title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2. MÉTODO IQR (Interquartile Range)\n",
    "def detect_outliers_iqr(df, columns, factor=1.5):\n",
    "\n",
    "    outliers_dict = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        \n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        \n",
    "        outliers_dict[col] = {\n",
    "            'count': len(outliers),\n",
    "            'percentage': len(outliers) / len(df) * 100,\n",
    "            'lower': lower_bound,\n",
    "            'upper': upper_bound\n",
    "        }\n",
    "    \n",
    "    return outliers_dict\n",
    "\n",
    "\n",
    "outliers_info = detect_outliers_iqr(train, num_continuous, factor=1.5)\n",
    "\n",
    "# Mostrar resumen\n",
    "print(\"RESUMEN DE OUTLIERS POR COLUMNA:\")\n",
    "for col, info in outliers_info.items():\n",
    "    print(f\"{col}: {info['count']} outliers ({info['percentage']:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. DEFINIR VARIABLES CONTINUAS (correctas para skew/outliers)\n",
    "# ============================================================\n",
    "\n",
    "num_continuous = [\n",
    "    \"duration_ms\",\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"loudness\",\n",
    "    \"speechiness\",\n",
    "    \"acousticness\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"valence\",\n",
    "    \"tempo\"\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 2. ANÁLISIS DE ASIMETRÍA (solo para decidir log-transform)\n",
    "# ============================================================\n",
    "\n",
    "print(\"ANÁLISIS DE ASIMETRÍA (SKEWNESS):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "skewness_results = {}\n",
    "for col in num_continuous:\n",
    "    s = train[col].skew()\n",
    "    skewness_results[col] = s\n",
    "    msg = \"MUY ASIMÉTRICA ⚠️\" if abs(s) > 1 else (\"Asimetría moderada\" if abs(s) > 0.5 else \"Simétrica ✓\")\n",
    "    print(f\"{col:20s}: skew = {s:6.2f}  --> {msg}\")\n",
    "\n",
    "# Variables muy asimétricas y positivas → aplicar log1p\n",
    "skewed_cols = [\n",
    "    col for col in num_continuous\n",
    "    if abs(skewness_results[col]) > 1 and (train[col] >= 0).all()\n",
    "]\n",
    "\n",
    "print(\"\\nColumnas seleccionadas para log transform:\", skewed_cols)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. TRANSFORMADOR LOGARÍTMICO (FUNCIONAL Y SIN ERRORES)\n",
    "# ============================================================\n",
    "\n",
    "class LogTransformer(FunctionTransformer):\n",
    "    \"\"\"\n",
    "    Transformador logarítmico seguro para pipelines\n",
    "    \"\"\"\n",
    "    def __init__(self, columns_to_transform):\n",
    "        self.columns_to_transform = columns_to_transform\n",
    "        super().__init__(\n",
    "            func=self._log_transform,\n",
    "            inverse_func=self._inverse_log_transform,\n",
    "            validate=False,\n",
    "            check_inverse=False   # ← NECESARIO PARA NO FALLAR\n",
    "        )\n",
    "\n",
    "    def _log_transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns_to_transform:\n",
    "            if col in X.columns:\n",
    "                X[col] = np.log1p(X[col])\n",
    "        return X\n",
    "\n",
    "    def _inverse_log_transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns_to_transform:\n",
    "            if col in X.columns:\n",
    "                X[col] = np.expm1(X[col])\n",
    "        return X\n",
    "\n",
    "\n",
    "log_transformer = LogTransformer(columns_to_transform=skewed_cols)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. DEFINIR COLUMNAS NUMÉRICAS Y CATEGÓRICAS (CORREGIDO)\n",
    "# ============================================================\n",
    "\n",
    "# Numéricas verdaderas\n",
    "num_cols = train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "num_cols.remove(\"popularity\")  # remover target\n",
    "\n",
    "# COLUMNAS CATEGÓRICAS DE BAJA CARDINALIDAD → SOLO ESTAS\n",
    "cat_cols = [\"key\", \"mode\", \"time_signature\", \"explicit\", \"track_genre\"]\n",
    "\n",
    "print(f\"\\nColumnas numéricas finales: {num_cols}\")\n",
    "print(f\"Columnas categóricas finales (baja cardinalidad): {cat_cols}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. PIPELINES NUMÉRICO Y CATEGÓRICO\n",
    "# ============================================================\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. COLUMN TRANSFORMER FINAL (SIN EXPLOTAR LA RAM)\n",
    "# ============================================================\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, num_cols),\n",
    "    (\"cat\", categorical_pipeline, cat_cols)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. PIPELINE COMPLETO CON MODELO\n",
    "# ============================================================\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"log_transform\", log_transformer),\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,\n",
    "        min_samples_split=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. ENTRENAMIENTO (SIN DATA LEAKAGE)\n",
    "# ============================================================\n",
    "\n",
    "X_train = train.drop(columns=[\"popularity\"])\n",
    "y_train = train[\"popularity\"]\n",
    "\n",
    "print(\"\\nEntrenando modelo...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"✓ Entrenamiento completado correctamente\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. Cargar test y predecir\n",
    "# ============================================================\n",
    "\n",
    "test_path = DATA / \"test.csv\"\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "y_pred = pipeline.predict(test)\n",
    "\n",
    "print(f\"\\n✓ Predicciones generadas: {len(y_pred)}\")\n",
    "print(f\"Rango de predicciones: {y_pred.min():.2f} – {y_pred.max():.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10. VISUALIZAR EFECTO DE LA TRANSFORMACIÓN LOGARÍTMICA\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(len(skewed_cols), 2, figsize=(12, len(skewed_cols)*3))\n",
    "\n",
    "for i, col in enumerate(skewed_cols):\n",
    "    ax0 = axes[i, 0] if len(skewed_cols) > 1 else axes[0]\n",
    "    ax1 = axes[i, 1] if len(skewed_cols) > 1 else axes[1]\n",
    "\n",
    "    ax0.hist(train[col], bins=50, color=\"red\", edgecolor=\"black\")\n",
    "    ax0.set_title(f\"{col} - Original (skew={train[col].skew():.2f})\")\n",
    "\n",
    "    transformed = np.log1p(train[col])\n",
    "    ax1.hist(transformed, bins=50, color=\"green\", edgecolor=\"black\")\n",
    "    ax1.set_title(f\"{col} - Log Transform (skew={transformed.skew():.2f})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f927c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../data/train_processed.csv\", index=False)\n",
    "test.to_csv(\"../data/test_processed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
